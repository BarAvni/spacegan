{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import libpysal\n",
    "import pysal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read from URL (Doesnt work for private repos)\n",
    "#url=\"https://github.com/konstantinklemmer/spacegan/raw/master/data/synth_data.csv\"\n",
    "#s=requests.get(url).content\n",
    "#data=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "#Read from local file\n",
    "data=pd.read_csv(\"C:/Users/Konstantin Klemmer/Documents/GitHub/spacegan/data/grid_augcsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pairwise distance matrix (Euclidean) between the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pysal.lib.cg.distance_matrix(np.array(data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `k` smallest distances (of the whole matrix, since the points are equally distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "u_dist = np.unique(dist)\n",
    "k_min_dist = np.sort(u_dist.flatten())[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spatial points object ([KDTree](https://pysal.readthedocs.io/en/dev/library/cg/kdtree.html))). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal.lib\n",
    "kd = pysal.lib.cg.kdtree.KDTree(np.array(data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute spatial neighbourhoods weight matrix by distance threshold (\"radius\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wnn = pysal.lib.weights.KNN(kd, 8, ids=data[\"id\"]) #KNN based weights\n",
    "#wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[1],binary=False,p=2) #Rook\n",
    "wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[2],binary=True,p=2) #Queen\n",
    "#wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[4],binary=True,p=2) #Queen 2nd degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial CV: Lat/Lon slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labels based on latitude / longitude binning and add the labels to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lon_group\"] = pd.cut(data[\"longitude\"],bins=5,labels=[1,2,3,4,5])\n",
    "data[\"lat_group\"] = pd.cut(data[\"latitude\"],bins=5,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method loops over our lat/lon groups, keeping each group as test data and the rest as train data. However, as we want to do spatial cross-validation, we remove neighbors of the test set. This can help to prevent model overfitting. Here, we remove 1st and 2nd degree neighbors, but the method can be adapted as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in list(data)[-2::]: #Loop over the two slicing label columns \n",
    "    data[\"s_id\"] = data[q] #Define which label column to use for slicing\n",
    "    \n",
    "    for j in np.unique(data[\"s_id\"]): #Loop over the unique labels in the slicing column \n",
    "        \n",
    "        test = data[data[\"s_id\"]==j] #Define test data \n",
    "        test[\"\"]\n",
    "        \n",
    "        temp_id = [] #Create empty neighbourhood index\n",
    "        \n",
    "        for k in test.index: #Fill neighborhood index using first degree neighbors of test data\n",
    "            temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[k]]).ravel().astype(np.int32))\n",
    "            \n",
    "        for l in temp_id: #Include second degree neighbors\n",
    "            temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[l]]).ravel().astype(np.int32))\n",
    "        \n",
    "        #for m in temp_id: #Include third degree neighbors\n",
    "        #    temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[m]]).ravel().astype(np.int32))\n",
    "            \n",
    "        train = data[data[\"s_id\"]!=j] #Define train data \n",
    "        train = train.drop(temp_id,errors=\"ignore\") #Exclude neighbors from index\n",
    "        \n",
    "        #INSERT DATA AUGMENTATION METHOD HERE\n",
    "        #train_aug = ...\n",
    "        \n",
    "        #INSERT MODEL TRAINING HERE\n",
    "        #model1 = f(train)\n",
    "        #predict = predict(model1,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the train and test data in our last iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data[\"longitude\"],data[\"latitude\"],color=\"grey\")\n",
    "plt.scatter(train[\"longitude\"],train[\"latitude\"],color=\"red\")\n",
    "plt.scatter(test[\"longitude\"],test[\"latitude\"],color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial CV: Leave-one-out (SLOO-CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method loops over every single observation as test points (as leave-one-out does) but excludes the neighbors of each test points. We can again define neighborhood structure as we wish; for now we again exclude 1st and 2nd degree neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[\"id\"]:\n",
    "        \n",
    "    test = data[data[\"id\"]==i]\n",
    "        \n",
    "    temp_id = []\n",
    "        \n",
    "    for k in test.index:\n",
    "        temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[k]]).ravel().astype(np.int32))\n",
    "            \n",
    "        for l in temp_id: #Include second degree neighbors\n",
    "            temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[l]]).ravel().astype(np.int32))\n",
    "        \n",
    "        #for m in temp_id: #Include third degree neighbors\n",
    "        #    temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[m]]).ravel().astype(np.int32))\n",
    "            \n",
    "        train = data[data[\"s_id\"]!=i]\n",
    "        train = train.drop(temp_id,errors=\"ignore\")\n",
    "        \n",
    "        #INSERT DATA AUGMENTATION METHOD HERE\n",
    "        #train_aug = ...\n",
    "        \n",
    "        #INSERT MODEL TRAINING HERE\n",
    "        #model1 = f(train)\n",
    "        #predict = predict(model1,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the train and test set look in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[\"longitude\"],data[\"latitude\"],color=\"grey\")\n",
    "plt.scatter(train[\"longitude\"],train[\"latitude\"],color=\"red\")\n",
    "plt.scatter(test[\"longitude\"],test[\"latitude\"],color=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
