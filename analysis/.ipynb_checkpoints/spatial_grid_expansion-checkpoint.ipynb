{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import libpysal\n",
    "import pysal\n",
    "import pysal.lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read from URL (Doesnt work for private repos)\n",
    "#url=\"https://github.com/konstantinklemmer/spacegan/raw/master/data/synth_data.csv\"\n",
    "#s=requests.get(url).content\n",
    "#data=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "#Read from local file\n",
    "data=pd.read_csv(\"C:/Users/Konstantin Klemmer/Documents/GitHub/spacegan/data/synth_data_ex1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.844504</td>\n",
       "      <td>1.370958</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.832568</td>\n",
       "      <td>-0.564698</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.793995</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.730340</td>\n",
       "      <td>0.632863</td>\n",
       "      <td>2.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.641493</td>\n",
       "      <td>0.404268</td>\n",
       "      <td>2.5</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         y         z  latitude  longitude\n",
       "0   1 -0.844504  1.370958       2.5        2.5\n",
       "1   2 -0.832568 -0.564698       2.5        7.5\n",
       "2   3 -0.793995  0.363128       2.5       12.5\n",
       "3   4 -0.730340  0.632863       2.5       17.5\n",
       "4   5 -0.641493  0.404268       2.5       22.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pairwise distance matrix (Euclidean) between the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = pysal.lib.cg.distance_matrix(np.array(data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `k` smallest distances (of the whole matrix, since the points are equally distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k=10\n",
    "#u_dist = np.unique(dist)\n",
    "#k_min_dist = np.sort(u_dist.flatten())[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spatial points object ([KDTree](https://pysal.readthedocs.io/en/dev/library/cg/kdtree.html))). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pysal.lib\n",
    "#kd = pysal.lib.cg.kdtree.KDTree(np.array(data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute spatial neighbourhoods weight matrix by distance threshold (\"radius\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wnn = pysal.lib.weights.KNN(kd, 8, ids=data[\"id\"]) #KNN based weights\n",
    "#wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[1],binary=False,p=2) #Rook\n",
    "#wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[2],binary=True,p=2) #Queen\n",
    "#wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[4],binary=True,p=2) #Queen 2nd degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Grid Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract points coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_expand(data,fact):\n",
    "    \n",
    "    #Copy column names from existing grid\n",
    "    new_points = pd.DataFrame(columns=data[[\"longitude\",\"latitude\"]].columns)\n",
    "    \n",
    "    #Create new grid:\n",
    "    #Expand longitude by factor `fact`\n",
    "    dst = (data[[\"longitude\"]].max() - data[[\"longitude\"]].min()) / (len(data.longitude.unique())-1)\n",
    "    exp = float(dst/fact)\n",
    "    x = []\n",
    "    d = float(data[[\"longitude\"]].min())\n",
    "    while d <= float(data[[\"longitude\"]].max()):\n",
    "        x.append(d)    \n",
    "        d = d + exp\n",
    "    #Expand latitude by factor `fact`\n",
    "    dst = (data[[\"latitude\"]].max() - data[[\"latitude\"]].min()) / (len(data.longitude.unique())-1)\n",
    "    exp = float(dst/fact)\n",
    "    y = []\n",
    "    d = float(data[[\"latitude\"]].min())\n",
    "    while d <= float(data[[\"latitude\"]].max()):\n",
    "        y.append(d)    \n",
    "        d = d + exp\n",
    "    #Bind new lat and lon values\n",
    "    lon = x * len(y)\n",
    "    lat = sorted(y*len(x))\n",
    "    #Create new points dataframe\n",
    "    new_points = pd.DataFrame({\"longitude\":lon,\"latitude\":lat})\n",
    "    #Merge with existing dataframe\n",
    "    new_data = pd.merge(new_points,data, how=\"left\", on=[\"longitude\",\"latitude\"])\n",
    "    #Create column to indicate whether observation is original or synthetic \n",
    "    new_data[\"synth\"] = 0\n",
    "    new_data.loc[new_data.id.isnull(), \"synth\"] = 1\n",
    "    #Re-assign IDs\n",
    "    new_data[[\"id\"]] = np.asarray(list(range(0,len(new_data[\"id\"])))).reshape(-1,1)\n",
    "    \n",
    "    #Spatial operations:\n",
    "    #Compute distance matrix of new grid\n",
    "    dist = pysal.lib.cg.distance_matrix(np.array(new_data[[\"longitude\",\"latitude\"]]))\n",
    "    #Extract and flatten 10 nearest distances\n",
    "    k=10\n",
    "    u_dist = np.unique(dist)\n",
    "    k_min_dist = np.sort(u_dist.flatten())[:k]\n",
    "    #Create KD tree\n",
    "    kd = pysal.lib.cg.kdtree.KDTree(np.array(new_data[[\"longitude\",\"latitude\"]]))\n",
    "    #Define neighbourhood (here Queen structure)\n",
    "    w = pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[2],binary=True,p=2) #Queen\n",
    "    \n",
    "    #Interpolate missing grid values\n",
    "    #OPTION 1:\n",
    "    #Interpolate new grid data based on mean of neighborhood\n",
    "    for k in new_data.index:\n",
    "        fill = new_data.iloc[k]\n",
    "        temp_id = []\n",
    "        if fill[\"synth\"] == 1:\n",
    "            temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[k]]).ravel().astype(np.int32))\n",
    "            neighbors = new_data.iloc[temp_id]\n",
    "            fill[\"z\"] = np.mean(neighbors[\"z\"])\n",
    "            fill[\"y\"] = np.mean(neighbors[\"y\"]) #Delete this line if OPTION 2 is preferred\n",
    "            new_data.iloc[k] = fill\n",
    "        else:\n",
    "            continue \n",
    "            \n",
    "    #OPTION 2:\n",
    "    #Interpolate Y using a linear model (works very poorly)\n",
    "\n",
    "    #from sklearn.linear_model import LinearRegression\n",
    "    #train = new_data[new_data[\"synth\"]==0]\n",
    "    #test = new_data[new_data[\"synth\"]==1]\n",
    "    #x_train = train[[\"longitude\",\"latitude\",\"z\"]]\n",
    "    #y_train = train[[\"y\"]]\n",
    "    #x_test = test[[\"longitude\",\"latitude\",\"z\"]]\n",
    "    #reg = LinearRegression().fit(x_train,y_train)\n",
    "    #y_pred = reg.predict(x_test)\n",
    "    #new_data[\"y\"][new_data[\"synth\"]==1] = y_pred\n",
    "    \n",
    "    #Return new dataframe\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = grid_expand(new_data,2)\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand grid by factor 2 (defined by the `exp` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand longitude (double)\n",
    "dst = (data[[\"longitude\"]].max() - data[[\"longitude\"]].min()) / (len(data.longitude.unique())-1)\n",
    "exp = float(dst/2)\n",
    "x = []\n",
    "d = float(data[[\"longitude\"]].min())\n",
    "while d <= float(data[[\"longitude\"]].max()):\n",
    "    x.append(d)    \n",
    "    d = d + exp\n",
    "\n",
    "#Expand latitude (double)\n",
    "dst = (data[[\"latitude\"]].max() - data[[\"latitude\"]].min()) / (len(data.longitude.unique())-1)\n",
    "exp = float(dst/fact)\n",
    "y = []\n",
    "d = float(data[[\"latitude\"]].min())\n",
    "while d <= float(data[[\"latitude\"]].max()):\n",
    "    y.append(d)    \n",
    "    d = d + exp\n",
    "\n",
    "lon = x * len(y)\n",
    "lat = sorted(y*len(x))\n",
    "\n",
    "new_points = pd.DataFrame({\"longitude\":lon,\"latitude\":lat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.merge(new_points,data, how=\"left\", on=[\"longitude\",\"latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[\"synth\"] = 0\n",
    "new_data.loc[new_data.id.isnull(), \"synth\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[[\"id\"]] = np.asarray(list(range(0,len(new_data[\"id\"])))).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pysal.lib.cg.distance_matrix(np.array(new_data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "u_dist = np.unique(dist)\n",
    "k_min_dist = np.sort(u_dist.flatten())[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd = pysal.lib.cg.kdtree.KDTree(np.array(new_data[[\"longitude\",\"latitude\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdist= pysal.lib.weights.distance.DistanceBand(kd, threshold=k_min_dist[2],binary=True,p=2) #Queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate new grid data based on mean of neighborhood\n",
    "for k in new_data.index:\n",
    "    fill = new_data.iloc[k]\n",
    "    temp_id = []\n",
    "    if fill[\"synth\"] == 1:\n",
    "        temp_id = np.unique(np.concatenate([temp_id,wdist.neighbors[k]]).ravel().astype(np.int32))\n",
    "        neighbors = new_data.iloc[temp_id]\n",
    "        fill[\"z\"] = np.mean(neighbors[\"z\"])\n",
    "        fill[\"y\"] = np.mean(neighbors[\"y\"])\n",
    "        new_data.iloc[k] = fill\n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate Y using a linear model (works very poorly)\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#train = new_data[new_data[\"synth\"]==0]\n",
    "#test = new_data[new_data[\"synth\"]==1]\n",
    "#x_train = train[[\"longitude\",\"latitude\",\"z\"]]\n",
    "#y_train = train[[\"y\"]]\n",
    "#x_test = test[[\"longitude\",\"latitude\",\"z\"]]\n",
    "#reg = LinearRegression().fit(x_train,y_train)\n",
    "#y_pred = reg.predict(x_test)\n",
    "#new_data[\"y\"][new_data[\"synth\"]==1] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method loops over our lat/lon groups, keeping each group as test data and the rest as train data. However, as we want to do spatial cross-validation, we remove neighbors of the test set. This can help to prevent model overfitting. Here, we remove 1st and 2nd degree neighbors, but the method can be adapted as needed. We create 10 folds (5 lon, 5 lat slicing) and save these in the columns `lat_group[1-5]` and `lon_group[1-5]`. For the values in each of these columns, `1` indicates testing data, `2` training data and `0`indicates data to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"grid_expanded_ex1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
